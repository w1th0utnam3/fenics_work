import os
import json
import pickle
from typing import Dict, List, Tuple

import numpy as np

from benchmarker.types import TestCase, BenchmarkReport, TestRunArgs, FormTestResult


def print_report(test_case: TestCase, report: BenchmarkReport):
    """Prints a report generated by execute_test."""

    print("")
    print("Benchmark report")
    print("-" * 20)
    print("Total runtime: {:.2f}s".format(report.total_runtime))

    # Get the length of the longest run args name
    longest_name = 0
    for run_arg_set in test_case.run_args:  # type: TestRunArgs
        longest_name = np.maximum(longest_name, len(run_arg_set.name))

    # Loop over results of all forms
    for form_idx, (form_name, form_results) in enumerate(report.results.items()):
        print("{}".format(form_name))
        print("Results for form '{}', test run with n={} elements".format(form_name, test_case.forms[form_idx].n_elems))

        for i, compiler_arg_set in enumerate(test_case.compiler_args):
            active_compile_args = [arg for arg, use in compiler_arg_set.items() if use]
            print("\tCompiled with flags '{}'".format(', '.join(active_compile_args)))

            for j, run_arg_set in enumerate(test_case.run_args):
                result = form_results[(i, j)]  # type: FormTestResult

                print(
                    "\t\t{:<{name_length}} | avg: {:>8.2f}ms | min: {:>8.2f}ms | max: {:>8.2f}ms | speedup: {:>5.2f}x | result: {:>20.14e} | result ok: {}".format(
                        run_arg_set.name,
                        result.avg * 1000,
                        result.min * 1000,
                        result.max * 1000,
                        result.speedup,
                        result.result_val,
                        result.result_ok,
                        name_length=longest_name + 1))

            print("")

        print("-" * 40)
        print("")


def save_generated_data(name: str, test_case: TestCase, test_fun_names: Dict, codes: List[Tuple[str, str]],
                        path: str = "", readable_source: bool = False):
    """
    Stores the specified generated test case data in a set of files.

    :param name: The base name for the set of files.
    :param test_case: The test case used to generate the data.
    :param test_fun_names: Output of the generate module. The dict listing the wrapper function names for each form.
    :param codes: Output of the generate module. The list of C source and header content tuples.
    :param path: Optional path where the files should be stored (otherwise uses working directory).
    :param readable_source: Whether the source and header files should be stored as plain text .c .h files.
        Otherwise, they are pickled into the data file.
    """

    output_basename = os.path.join(path, name)

    n_code_files = len(codes)
    with open(output_basename + ".bdata", mode="wb") as f:
        if readable_source:
            pickle.dump((test_case, test_fun_names, n_code_files, []), f)
        else:
            pickle.dump((test_case, test_fun_names, n_code_files, codes), f)

    if readable_source:
        def store_string(filename: str, content: str):
            with open(filename, mode="w") as f:
                f.write(content)

        for i, (code_c, code_h) in enumerate(codes):
            store_string(output_basename + "_code_{}.c".format(i), code_c)
            store_string(output_basename + "_code_{}.h".format(i), code_h)


def load_generated_data(name: str, path: str = "") -> Tuple[TestCase, Dict, List[Tuple[str, str]]]:
    """
    Loads a set of generated test case data from files.

    :param name: The base name for the set of files as given to the save function.
    :param path: Optional path where the file are stored (otherwise uses working directory).
    :return: Tuple that can be used as input to run a benchmark.
    """

    input_basename = os.path.join(path, name)

    with open(input_basename + ".bdata", mode="rb") as f:
        test_case, test_fun_names, n_code_files, codes = pickle.load(f)

    if len(codes) != n_code_files:
        def load_string(filename: str) -> str:
            with open(filename, mode="r") as f:
                content = f.read()
                return content

        codes = []
        for i in range(n_code_files):
            code_c = load_string(input_basename + "_code_{}.c".format(i))
            code_h = load_string(input_basename + "_code_{}.h".format(i))
            codes.append((code_c, code_h))

    return test_case, test_fun_names, codes


def save_report(filename: str, test_case: TestCase, report: BenchmarkReport):
    """Stores a BenchmarkReport and its TestCase to the specified file."""

    with open(filename, mode="wb") as f:
        pickle.dump((test_case, report), f)


def load_report(filename: str) -> Tuple[TestCase, BenchmarkReport]:
    """Loads a BenchmarkReport and its TestCase from the specified file."""

    with open(filename, mode="rb") as f:
        test_case, report = pickle.load(f)

    return test_case, report
